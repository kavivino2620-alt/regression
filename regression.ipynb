{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "e240387c-fddb-4982-89cb-580cf777e819",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f334b08a-8c9d-4310-bf5c-bccf87a783f5",
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# 1. Generate synthetic dataset\nX, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 2. Custom Logistic Regression\nclass CustomLogisticRegression:\n    def __init__(self, learning_rate=0.01, iterations=1000):\n        self.learning_rate = learning_rate\n        self.iterations = iterations\n\n    def sigmoid(self, z):\n        return 1 / (1 + np.exp(-z))\n\n    def cost_function(self, h, y):\n        m = y.shape[0]\n        return (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n\n    def fit(self, X, y):\n        m, n = X.shape\n        self.theta = np.zeros(n)\n        self.bias = 0\n\n        for _ in range(self.iterations):\n            linear_model = np.dot(X, self.theta) + self.bias\n            h = self.sigmoid(linear_model)\n\n            d_theta = (1 / m) * np.dot(X.T, (h - y))\n            d_bias = (1 / m) * np.sum(h - y)\n\n            self.theta -= self.learning_rate * d_theta\n            self.bias -= self.learning_rate * d_bias\n\n    def predict(self, X):\n        linear_model = np.dot(X, self.theta) + self.bias\n        h = self.sigmoid(linear_model)\n        return [1 if i >= 0.5 else 0 for i in h]\n\n# 3. Train and evaluate custom model\ncustom_model = CustomLogisticRegression(learning_rate=0.1, iterations=1000)\ncustom_model.fit(X_train, y_train)\ny_pred_custom = custom_model.predict(X_test)\n\n# 4. Train and evaluate scikit-learn model\nsk_model = LogisticRegression()\nsk_model.fit(X_train, y_train)\ny_pred_sk = sk_model.predict(X_test)\n\n# 5. Metrics\ndef print_metrics(name, y_true, y_pred):\n    print(f\"{name} Accuracy:\", accuracy_score(y_true, y_pred))\n    print(f\"{name} Precision:\", precision_score(y_true, y_pred))\n    print(f\"{name} Recall:\", recall_score(y_true, y_pred))\n    print(f\"{name} F1 Score:\", f1_score(y_true, y_pred))\n    print()\n\nprint_metrics(\"Custom Model\", y_test, y_pred_custom)\nprint_metrics(\"Scikit-learn Model\", y_test, y_pred_sk)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Custom Model Accuracy: 0.88\nCustom Model Precision: 0.8787878787878788\nCustom Model Recall: 0.8787878787878788\nCustom Model F1 Score: 0.8787878787878788\n\nScikit-learn Model Accuracy: 0.88\nScikit-learn Model Precision: 0.8787878787878788\nScikit-learn Model Recall: 0.8787878787878788\nScikit-learn Model F1 Score: 0.8787878787878788\n\n"
        }
      ],
      "execution_count": 1
    }
  ]
}